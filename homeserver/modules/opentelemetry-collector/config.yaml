receivers:
  otlp:
    protocols:
      grpc:
        endpoint: "127.0.0.1:4317"
  hostmetrics:
    collection_interval: 1m
    scrapers:
      cpu:
        metrics:
          system.cpu.time: { enabled: false }
          system.cpu.utilization: { enabled: true }
      memory:
        metrics:
          system.memory.usage: { enabled: false }
          system.memory.utilization: { enabled: true }
      network:
        include:
          interfaces: ["end0"]
          match_type: strict
        metrics:
          system.network.connections: { enabled: true }
          system.network.dropped: { enabled: false }
          system.network.errors: { enabled: false }
          system.network.io: { enabled: true }
          system.network.packets: { enabled: false }
  hostmetrics/fs:
    collection_interval: 60m
    scrapers:
      filesystem:
        exclude_mount_points:
          mount_points: ["/nix/store"]
          match_type: strict
        metrics:
          system.filesystem.inodes.usage: { enabled: false }
          system.filesystem.usage: { enabled: false }
          system.filesystem.utilization: { enabled: true }

processors:
  memory_limiter:
    check_interval: 10s
    # hard limit
    limit_mib: 500
    # sort limit 400
    spike_limit_mib: 100
  resourcedetection/system:
    detectors: ["system"]
    override: false
    attributes: ["host.name"]
    system:
      hostname_sources: ["os"]
  filter/metrics:
    error_mode: propagate
    metrics:
      datapoint:
        - >-
          metric.name == "system.cpu.utilization" 
          and 
          ( 
            attributes["state"] == "nice" 
            or 
            attributes["state"] == "softirq" 
            or 
            attributes["state"] == "steal" 
            or 
            attributes["state"] == "interrupt" 
          ) 
        - >-
          metric.name == "system.network.connections"
          and
          attributes["state"] != "ESTABLISHED"
          and
          attributes["state"] != "LISTEN"
  batch/metrics:
    send_batch_size: 8192
    timeout: 3s
    send_batch_max_size: 16384

exporters:
  logging:
    verbosity: "normal"
  prometheusremotewrite/openobserve:
    endpoint: https://api.openobserve.ai/api/${env:OPEN_OBSERVE_ORG}/prometheus/api/v1/write
    headers:
      Authorization: Basic ${env:OPEN_OBSERVE_TOKEN}
    resource_to_telemetry_conversion:
      enabled: true

extensions:
  memory_ballast:
    size_mib: 64

service:
  extensions: [memory_ballast]
  pipelines:
    metrics:
      receivers: 
        - otlp
        - hostmetrics
        - hostmetrics/fs
      processors: 
        - memory_limiter
        - resourcedetection/system
        - filter/metrics
        - batch/metrics
      exporters: 
        - logging
        - prometheusremotewrite/openobserve
